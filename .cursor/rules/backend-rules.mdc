---
description: 
globs: packages/server/**.*
alwaysApply: false
---
Below is a lean “cheat-sheet” version of your guide—same core rules, minimal repetition, sized for fast LLM ingestion. Let me know if you’d like any section expanded or trimmed further!

---

# Backend Architecture Cheat-Sheet

## 1  Layer Overview
Route (Hono + @hono/zod-openapi) → Service (business logic + DB) → Utilities → SQLite DB  
All data shapes are declared **once** as Zod schemas in `packages/shared`. Services parse rows immediately; everything downstream works with typed objects.

## 2  Directory Map
| Layer | Folder |
|-------|--------|
| Routes   | `packages/server/src/routes` |
| Services | `packages/server/src/services` |
| Schemas  | `packages/shared/src/schemas` |
| Utilities| `packages/server/src/services/*-service.ts` |
| Database | `packages/server/src/utils/database.ts` |

## 3  Naming & Conventions
| Kind    | File suffix        | Key rules |
|---------|--------------------|-----------|
| **Schema**  | `*.schemas.ts`   | `.openapi('Name')`, include `example`/`description`, export `z.infer` alias |
| **Service** | `*-service.ts`   | Validate rows immediately, return typed promises, throw `ApiError` |
| **Route**   | `*-routes.ts`    | `createRoute()` + `.openapi()`, responses `satisfies z.infer<>` |
| **Tests**   | `*.test.ts`      | Run with `bun test` |

> **Golden Rule:** raw data is validated **once** (in a Service) and never leaks further.

## 4  Quick Templates
```ts
// Schema
export const FooSchema = z.object({ id: z.string() }).openapi('Foo');
export type Foo = z.infer<typeof FooSchema>;

// Service
export async function getFoo(id: string): Promise<Foo | null> {
  const row = db.prepare('SELECT * FROM foo WHERE id=?').get(id);
  return row ? FooSchema.parse(row) : null;
}

// Route
const getFoo = createRoute({
  method: 'get', path: '/foo/{id}',
  responses: { 200: { content: { 'application/json': { schema: FooSchema } } } },
});
api.openapi(getFoo, async c => {
  const { id } = c.req.valid('param');
  const foo = await getFoo(id);
  if (!foo) throw new ApiError(404, 'Foo not found', 'FOO_NOT_FOUND');
  return c.json(foo, 200);
});
```

## 5  Gen-AI Endpoints
| Path | Purpose | Helper | Extra headers |
|------|---------|--------|---------------|
| `POST /ai/chat` | Streaming chat | `handleChatMessage()` | `Content-Type: text/event-stream; Cache-Control: no-cache` |
| `POST /ai/generate/text` | One-shot text | `generateSingleText()` | — |
| `POST /api/gen-ai/structured` | Prompt → JSON | `generateStructuredData()` | — |

## 6  Unified Provider Service
Always call LLMs through `unified-provider-service.ts`.  
Helpers: `handleChatMessage`, `generateSingleText`, `generateStructuredData`.  
Keys come from `provider-key-service`; Ollama/LM Studio treated as OpenAI-compatible.