#!/usr/bin/env bun

/**
 * Test runner for local AI model endpoints
 * 
 * Usage:
 *   bun run test-local-models.ts                    # Run all tests
 *   bun run test-local-models.ts --check-only       # Just check if LMStudio is available
 *   bun run test-local-models.ts --mock             # Run with mock responses (no LMStudio needed)
 */

import { $ } from 'bun'

const args = process.argv.slice(2)
const checkOnly = args.includes('--check-only')
const useMock = args.includes('--mock')

const LMSTUDIO_URL = process.env.LMSTUDIO_BASE_URL || 'http://192.168.1.38:1234'

async function checkLMStudioConnection(): Promise<boolean> {
  console.log(`\nüîç Checking LMStudio connection at ${LMSTUDIO_URL}...`)
  
  try {
    const response = await fetch(`${LMSTUDIO_URL}/v1/models`)
    if (!response.ok) {
      console.error(`‚ùå LMStudio returned status ${response.status}`)
      return false
    }
    
    const data = await response.json()
    const models = data.data || []
    
    console.log(`‚úÖ LMStudio is running with ${models.length} model(s) loaded:`)
    models.forEach((model: any) => {
      console.log(`   - ${model.id}`)
    })
    
    // Check for gpt-oss:20b specifically
    const hasTargetModel = models.some((m: any) => 
      m.id === 'gpt-oss:20b' || m.id.includes('gpt-oss')
    )
    
    if (!hasTargetModel) {
      console.warn(`\n‚ö†Ô∏è  Warning: gpt-oss:20b model not found in LMStudio`)
      console.warn(`   Please load the model in LMStudio for best results`)
    }
    
    return true
  } catch (error) {
    console.error(`‚ùå Failed to connect to LMStudio:`, error)
    return false
  }
}

async function runTests() {
  console.log('\nüß™ Running Local AI Model Tests')
  console.log('================================\n')
  
  const env = {
    LMSTUDIO_BASE_URL: LMSTUDIO_URL,
    NODE_ENV: 'test',
    ...(useMock ? { SKIP_LMSTUDIO_TESTS: 'true' } : {})
  }
  
  const tests = [
    {
      name: 'File Summarization Tests',
      command: 'bun test packages/services/src/tests/file-summarization.test.ts --timeout 30000'
    },
    {
      name: 'E2E Workflow Tests',
      command: 'bun test packages/services/src/tests/e2e/summarization-workflow.test.ts --timeout 90000'
    }
  ]
  
  let passed = 0
  let failed = 0
  
  for (const test of tests) {
    console.log(`\nüìã ${test.name}`)
    console.log('‚îÄ'.repeat(40))
    
    try {
      await $`${test.command}`.env(env)
      console.log(`‚úÖ ${test.name} passed`)
      passed++
    } catch (error) {
      console.error(`‚ùå ${test.name} failed`)
      failed++
    }
  }
  
  console.log('\n' + '='.repeat(40))
  console.log('üìä Test Results Summary')
  console.log(`   ‚úÖ Passed: ${passed}`)
  console.log(`   ‚ùå Failed: ${failed}`)
  console.log(`   üìà Total: ${passed + failed}`)
  
  return failed === 0
}

async function main() {
  try {
    // Check LMStudio connection
    const isConnected = await checkLMStudioConnection()
    
    if (checkOnly) {
      process.exit(isConnected ? 0 : 1)
    }
    
    if (!isConnected && !useMock) {
      console.log('\n‚ö†Ô∏è  LMStudio is not available')
      console.log('   Options:')
      console.log('   1. Start LMStudio and load the gpt-oss:20b model')
      console.log('   2. Run with mock responses: bun run test-local-models.ts --mock')
      console.log('   3. Set LMSTUDIO_BASE_URL to a different address')
      process.exit(1)
    }
    
    if (useMock) {
      console.log('\nüé≠ Running tests with mock responses (no LMStudio required)')
    }
    
    // Run the tests
    const success = await runTests()
    
    if (success) {
      console.log('\n‚ú® All tests passed!')
    } else {
      console.log('\nüí• Some tests failed')
    }
    
    process.exit(success ? 0 : 1)
    
  } catch (error) {
    console.error('\nüî• Unexpected error:', error)
    process.exit(1)
  }
}

// Run the script
main()